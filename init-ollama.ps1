# Script de inicializaciÃ³n de Ollama para Windows
# Este script configura Ollama con los modelos necesarios

Write-Host "ğŸš€ Deteniendo servicios existentes..." -ForegroundColor Yellow
docker-compose down

Write-Host "ğŸ”„ Iniciando servicios (esto puede tomar unos minutos)..." -ForegroundColor Green
docker-compose up -d

Write-Host "â³ Esperando a que Ollama estÃ© listo..." -ForegroundColor Blue
Start-Sleep -Seconds 20

Write-Host "ğŸ” Verificando estado de Ollama..." -ForegroundColor Cyan
$maxRetries = 10
$retryCount = 0

do {
    try {
        $response = Invoke-RestMethod -Uri "http://localhost:11434/api/tags" -Method GET -TimeoutSec 5
        Write-Host "âœ… Ollama estÃ¡ respondiendo!" -ForegroundColor Green
        break
    catch {
        $retryCount++
        Write-Host "â³ Intento $retryCount/$maxRetries - Esperando a Ollama..." -ForegroundColor Yellow
        Start-Sleep -Seconds 10
    }
} while ($retryCount -lt $maxRetries)

if ($retryCount -eq $maxRetries) {
    Write-Host "âŒ Error: Ollama no responde despuÃ©s de $maxRetries intentos" -ForegroundColor Red
    Write-Host "ğŸ”§ Verifica los logs: docker-compose logs ollama" -ForegroundColor Yellow
    exit 1
}

Write-Host "ğŸ“¥ Descargando Llama 3.2:3b (modelo ligero y rÃ¡pido)..." -ForegroundColor Blue
Write-Host "   Esto puede tomar 5-10 minutos dependiendo de tu conexiÃ³n..." -ForegroundColor Gray
docker-compose exec ollama ollama pull llama3.2:3b

if ($LASTEXITCODE -eq 0) {
    Write-Host "âœ… Llama 3.2:3b descargado correctamente!" -ForegroundColor Green
} else {
    Write-Host "âš ï¸ Error descargando Llama 3.2:3b, intentando con modelo alternativo..." -ForegroundColor Yellow
    docker-compose exec ollama ollama pull llama3:8b
}

Write-Host "ğŸ§ª Probando conexiÃ³n con el modelo..." -ForegroundColor Magenta
$testResponse = docker-compose exec ollama ollama run llama3.2:3b "Responde solo: CONEXION OK"

if ($testResponse -like "*CONEXION OK*") {
    Write-Host "âœ… Â¡IA local configurada correctamente!" -ForegroundColor Green
} else {
    Write-Host "âš ï¸ El modelo se descargÃ³ pero hay problemas en la respuesta" -ForegroundColor Yellow
}

Write-Host ""
Write-Host "ğŸ‰ Â¡ConfiguraciÃ³n completada!" -ForegroundColor Green
Write-Host "ğŸ“± Servicios disponibles:" -ForegroundColor Cyan
Write-Host "   ğŸŒ Frontend: http://localhost:8501" -ForegroundColor White
Write-Host "   ğŸ”§ Backend: http://localhost:8000" -ForegroundColor White  
Write-Host "   ğŸ¤– Ollama: http://localhost:11434" -ForegroundColor White
Write-Host "   ğŸ—„ï¸ ChromaDB: http://localhost:8001" -ForegroundColor White
Write-Host ""
Write-Host "ğŸ’¡ Ahora puedes usar el copiloto con IA local!" -ForegroundColor Yellow
Write-Host "   Ve a http://localhost:8501 y verÃ¡s 'IA Local Activa'" -ForegroundColor Gray
